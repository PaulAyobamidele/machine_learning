{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138da089",
   "metadata": {},
   "source": [
    "# Lab 3: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fbf60",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "## Task 0: Execute each cell sequentially and ensure comprehension of the code in each.\n",
    "## Task 1: Apply the same code to the diabetes dataset. Remember to adjust the evaluation method since the target variable is continuous.\n",
    "## Task 2: Using the custom_rfe function, implement forward feature selection (custom_fss)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84346346",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b90528",
   "metadata": {},
   "source": [
    "Regression analyzes connections between variables, such as examining how employee salaries are influenced by factors like experience, education level, job role, and location within a company. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09ce66",
   "metadata": {},
   "source": [
    "Let's begin with the fundamental concept of linear regression, which involves fitting a straight line to our data. This linear model takes the form:\n",
    "\n",
    "$$ y = a_0 + a_1 x_1 + a_2 x_2 + ... $$\n",
    "\n",
    "Here, $a_1$ $a_2$ $...$ represents the slopes and $a_0$ represents the intercept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b809a5",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06653d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape # feature matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809686f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target.shape # target vector shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a784b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names # column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# converting data to pandas dataframe\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                  columns= iris['feature_names'] + ['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot scatterplot of the Iris dataset\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.pairplot(df, hue='target', palette='viridis')\n",
    "plt.suptitle(\"Scatterplot of Iris Dataset\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671d171",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f17b9",
   "metadata": {},
   "source": [
    "### Using one feature at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b34280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sepal length (cm)'].values.reshape(-1,1)\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efb9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f4174d",
   "metadata": {},
   "source": [
    "Linear Regression assumes the following model: \n",
    " \n",
    " $y = X\\beta + c + \\epsilon$\n",
    " \n",
    " X data <br />\n",
    " $\\beta$ coefficients <br />\n",
    " c intercept <br />\n",
    " $\\epsilon$ error, cannot explained by model <br />\n",
    " y target <br />\n",
    " \n",
    " Using scikit-learn, linear regression is very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a06ad",
   "metadata": {},
   "source": [
    "We can use Scikit-Learn's LinearRegression estimator to fit this data and construct the best-fit line, as shown in  following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Sperate train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the linear regression model:\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d7d86",
   "metadata": {},
   "source": [
    "After fitting the model, you can play it in the folowing ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_ # Get the coefficients, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_ # Get the intercept, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf867627",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)\n",
    "# Predict unkown data\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322f53a",
   "metadata": {},
   "source": [
    "### plot actual data vs predicted line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatterplot with regression line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test, y_test, color='black', label='Actual')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3, label='Predicted')\n",
    "plt.xlabel('Petal Width (cm)')\n",
    "plt.ylabel('Species')\n",
    "plt.title('Linear Regression on Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Convert predicted values to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8924ef07",
   "metadata": {},
   "source": [
    "### Using second feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39baf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sepal width (cm)'].values.reshape(-1,1)\n",
    "y = df['target'].values\n",
    "\n",
    "# Sperate train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Predict unkown data\n",
    "y_pred\n",
    "\n",
    "\n",
    "# Convert predicted values to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807cf2f2",
   "metadata": {},
   "source": [
    "### Using third feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ddd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['petal length (cm)'].values.reshape(-1,1)\n",
    "y = df['target'].values\n",
    "\n",
    "# Sperate train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Predict unkown data\n",
    "y_pred\n",
    "\n",
    "\n",
    "# Convert predicted values to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443694e9",
   "metadata": {},
   "source": [
    "### Using fourth feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80402eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['petal width (cm)'].values.reshape(-1,1)\n",
    "y = df['target'].values\n",
    "\n",
    "# Sperate train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Predict unkown data\n",
    "y_pred\n",
    "\n",
    "\n",
    "# Convert predicted values to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d710fd8",
   "metadata": {},
   "source": [
    "### Using all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                  columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "# Select features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred_int, average='weighted')\n",
    "print(\"F1-score with all features:\", f1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3659e4d",
   "metadata": {},
   "source": [
    "## bruteforce search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def brute_force_feature_selection(X, y, model, tolerance=0.95):\n",
    "    \"\"\"\n",
    "    Perform brute-force feature selection by iterating over all possible combinations of features.\n",
    "    \n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Input features.\n",
    "        y (numpy.ndarray): Target variable.\n",
    "        model: Model to be used for training.\n",
    "        tolerance (float): Tolerance level for accuracy.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Table with used features and accuracy.\n",
    "    \"\"\"\n",
    "    num_features = X.shape[1]\n",
    "    feature_names = [f'Feature {i+1}' for i in range(num_features)]\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over all possible combinations of features\n",
    "    for r in range(1, num_features+1):\n",
    "        for combination in combinations(range(num_features), r):\n",
    "            X_subset = X[:, combination]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, np.round(y_pred).astype(int))\n",
    "            # Append results to the list\n",
    "            results.append([list(combination), accuracy])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['Used Features', 'Accuracy'])\n",
    "    return results_df\n",
    "\n",
    "# Example usage:\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "model = LinearRegression()\n",
    "results_df = brute_force_feature_selection(X, y, model, tolerance=0.95)\n",
    "\n",
    "sorted_results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "sorted_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673ab82",
   "metadata": {},
   "source": [
    "### Using recursive feature elimination:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab4718",
   "metadata": {},
   "source": [
    "the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable.\n",
    "\n",
    "Then, the least important features are pruned from current set of features.\n",
    "\n",
    "That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7652004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Recursive Feature Elimination (RFE) from scratch with accuracy\n",
    "def custom_rfe(model, X_train, X_test, y_train, y_test):\n",
    "    num_features = X_train.shape[1]\n",
    "    selected_features = list(range(num_features))\n",
    "    best_accuracy = 0\n",
    "    best_feature_set = selected_features.copy()\n",
    "    while len(selected_features) > 1:\n",
    "        worst_feature = None\n",
    "        min_coefficient = float('inf')\n",
    "        for feature in selected_features:\n",
    "            features_subset = selected_features.copy()\n",
    "            features_subset.remove(feature)\n",
    "            X_train_subset = X_train[:, features_subset]\n",
    "            X_test_subset = X_test[:, features_subset]\n",
    "            model.fit(X_train_subset, y_train)\n",
    "            y_pred = model.predict(X_test_subset)\n",
    "            accuracy = accuracy_score(y_test, np.round(y_pred).astype(int))\n",
    "            print(\"features_subset : \", features_subset , \"accuracy: \",accuracy)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature_set = features_subset.copy()\n",
    "            coefficients = np.abs(model.coef_)\n",
    "            if np.min(coefficients) < min_coefficient:\n",
    "                min_coefficient = np.min(coefficients)\n",
    "                worst_feature = feature\n",
    "        print(\"worst_feature: \", worst_feature)\n",
    "        selected_features.remove(worst_feature)\n",
    "    return best_feature_set\n",
    "\n",
    "# Perform RFE to select features\n",
    "selected_features = custom_rfe(model, X_train, X_test, y_train, y_test)\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Transform the training and testing datasets to include only the selected features\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "# Train the Linear Regression model with the selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, np.round(y_pred).astype(int))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25e751",
   "metadata": {},
   "source": [
    "### using the python predefined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "help(RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4194801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                  columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "# Select features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform linear regression\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform Recursive Feature Elimination\n",
    "rfe = RFE(estimator=model, n_features_to_select=3, step=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Train model using selected features\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "# Convert predictions to integer (rounding to nearest)\n",
    "y_pred_int = np.round(y_pred).astype(int)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred_int, average='weighted')\n",
    "print(\"F1-score with selected features:\", f1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_int)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266ba64",
   "metadata": {},
   "source": [
    "## You have successfully finished Task0.\n",
    "## Now you can make changes to do Task 1.\n",
    "## Task 1: Apply the same code to the diabetes dataset. Remember to adjust the evaluation method since the target variable is continuous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reproduce the same notebook using diabete dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabets = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabets.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8aadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
